import os
import threading
import speech_recognition as sr
from flask import Flask, render_template, jsonify, request
import google.generativeai as genai
from speak import speak_text  # Yeni eklenen satÄ±r

app = Flask(__name__)

status = "HazÄ±r"
listening = False
listener_thread = None

# Google Gemini ayarÄ±
genai.configure(api_key="AIzaSyBRtVTPJdhPG-G-ywr96_niK-R6CSJeSI0")
model = genai.GenerativeModel("gemini-2.0-flash")
system_prompt = """Sen bir sanal asistansÄ±n doÄŸru cevaplar ver Ã§ok uzatma."""

recognizer = sr.Recognizer()
microphone = sr.Microphone()

#chd
def generate_smart_reply(question):
    # Zorluk seviyesini tahmin et
    eval_prompt = f"Soru: \"{question}\"\nBu soru karmaÅŸÄ±k mÄ±? EÄŸer Ã¶yleyse 'ZOR' yaz, deÄŸilse 'KOLAY' yaz."
    eval = model.generate_content(eval_prompt).text.strip().upper()

    if "ZOR" in eval:
        # Chain of Draft uygula
        draft_prompt = f"Soruya cevap vermeden Ã¶nce dÃ¼ÅŸÃ¼nce taslaÄŸÄ± Ã¼ret.\nSoru: {question}\nTaslak:"
        draft = model.generate_content(draft_prompt).text

        final_prompt = f"""AÅŸaÄŸÄ±da bir soru ve bu soruya yÃ¶nelik bir dÃ¼ÅŸÃ¼nce taslaÄŸÄ± verilmiÅŸtir.
Bu taslaÄŸÄ± kullanarak aÃ§Ä±k, net ve mantÄ±klÄ± bir nihai cevap Ã¼ret.

Soru: {question}

Taslak:
{draft}

Nihai cevap:"""
        answer = model.generate_content(final_prompt).text.strip()
    else:
        # Basit soru, direkt cevap
        full_prompt = f"{system_prompt}\nKullanÄ±cÄ±: {question}"
        answer = model.generate_content([{"role": "user", "parts": [full_prompt]}]).text.strip()

    return answer


#chd


with microphone as source:
    print("ğŸ”§ Kalibrasyon yapÄ±lÄ±yor...")
    recognizer.adjust_for_ambient_noise(source, duration=2)

def play_audio(filename):
    if os.name == 'nt':
        os.system(f'start {filename}')
    else:
        os.system(f'mpg123 {filename}')  # Linux iÃ§in mp3 Ã§alÄ±cÄ± komutu

def recognize_and_respond():
    global status, listening
    while listening:
        with microphone as source:
            status = "Dinliyor"
            print("ğŸ™ï¸ Dinleniyor...")
            audio = recognizer.listen(source, phrase_time_limit=10)

        try:
            user_input = recognizer.recognize_google(audio, language="tr-TR")
            print(f"ğŸ‘¤ Siz: {user_input}")

            if user_input.lower() in ["Ã§Ä±k", "kapat", "gÃ¶rÃ¼ÅŸÃ¼rÃ¼z", "bitir"]:
                status = "Durduruldu"
                listening = False
                break

            status = "YanÄ±tlanÄ±yor"
            answer = generate_smart_reply(user_input)


            print("ğŸ¤– AKÃœBOT:", answer)

            # XTTS ile ses Ã¼ret ve Ã§al
            output_path = speak_text(answer, output_path="static/output.wav")
            play_audio(output_path)

            status = "HazÄ±r"

        except sr.UnknownValueError:
            print("â“ AnlaÅŸÄ±lamadÄ±.")
            status = "AnlaÅŸÄ±lamadÄ±"
        except sr.RequestError:
            print("ğŸš« STT hatasÄ±")
            status = "STT HatasÄ±"

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/status")
def get_status():
    return jsonify({"status": status})

@app.route("/start", methods=["POST"])
def start_listening():
    global listening, listener_thread, status
    if not listening:
        listening = True
        listener_thread = threading.Thread(target=recognize_and_respond)
        listener_thread.start()
        status = "BaÅŸlatÄ±ldÄ±"
    return jsonify({"message": "Dinleme baÅŸlatÄ±ldÄ±."})

@app.route("/stop", methods=["POST"])
def stop_listening():
    global listening, status
    listening = False
    status = "Durduruldu"
    return jsonify({"message": "Dinleme durduruldu."})

if __name__ == "__main__":
    app.run(debug=True)
